{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfq_UqhjCZUP"
   },
   "source": [
    "# DTSC670: Foundations of Machine Learning Models\n",
    "## Module 2\n",
    "## Assignment 4: Custom Transformer and Transformation Pipeline\n",
    "\n",
    "#### Name: Trenton Middleton\n",
    "\n",
    "Begin by writing your name above.\n",
    "\n",
    "Your task in this assignment is to create a custom transformation pipeline that takes in raw data and returns fully prepared, clean data that is ready for model training.  However, we will not actually train any models in this assignment.  This pipeline will employ an imputer class, a user-defined transformer class, and a data-normalization class.\n",
    "\n",
    "Please note that the order of features in the final feature matrix must be correct.  See the below figure that illustrates the input and output of the transformation pipeline.  The positions of features $x_1$ and $x_2$ do not change - they remain in the first and second columns, respectvely, both before and after the transformation pipeline.  In the transformed dataset, the $x_5$ feature is next, and is followed by the newly computed feature $x_6$.  Finally, the last two columns are the remaining one-hot vectors obtained from encoding the categorical feature $x_3$.\n",
    "\n",
    "<img src=\"DataTransformation.png \" width =\"500\" />\n",
    "\n",
    "# Import Data\n",
    "\n",
    "Import data from the file called `CustomTransformerData.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "w9WJuw4xCZUS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.5</td>\n",
       "      <td>2.354153</td>\n",
       "      <td>COLD</td>\n",
       "      <td>593</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.314048</td>\n",
       "      <td>WARM</td>\n",
       "      <td>340</td>\n",
       "      <td>2.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.5</td>\n",
       "      <td>4.021604</td>\n",
       "      <td>COLD</td>\n",
       "      <td>551</td>\n",
       "      <td>4.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COLD</td>\n",
       "      <td>2368</td>\n",
       "      <td>6.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.5</td>\n",
       "      <td>5.847601</td>\n",
       "      <td>WARM</td>\n",
       "      <td>2636</td>\n",
       "      <td>10.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.5</td>\n",
       "      <td>7.229910</td>\n",
       "      <td>WARM</td>\n",
       "      <td>2779</td>\n",
       "      <td>14.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.5</td>\n",
       "      <td>7.997255</td>\n",
       "      <td>HOT</td>\n",
       "      <td>1057</td>\n",
       "      <td>18.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.5</td>\n",
       "      <td>9.203947</td>\n",
       "      <td>COLD</td>\n",
       "      <td>819</td>\n",
       "      <td>24.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.5</td>\n",
       "      <td>10.335348</td>\n",
       "      <td>WARM</td>\n",
       "      <td>3349</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.5</td>\n",
       "      <td>11.112142</td>\n",
       "      <td>HOT</td>\n",
       "      <td>3235</td>\n",
       "      <td>36.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.5</td>\n",
       "      <td>11.759611</td>\n",
       "      <td>WARM</td>\n",
       "      <td>216</td>\n",
       "      <td>44.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.5</td>\n",
       "      <td>12.629096</td>\n",
       "      <td>WARM</td>\n",
       "      <td>2529</td>\n",
       "      <td>52.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.5</td>\n",
       "      <td>14.082589</td>\n",
       "      <td>COLD</td>\n",
       "      <td>1735</td>\n",
       "      <td>60.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.5</td>\n",
       "      <td>14.657678</td>\n",
       "      <td>HOT</td>\n",
       "      <td>1254</td>\n",
       "      <td>70.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HOT</td>\n",
       "      <td>1245</td>\n",
       "      <td>80.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.5</td>\n",
       "      <td>17.184114</td>\n",
       "      <td>WARM</td>\n",
       "      <td>310</td>\n",
       "      <td>90.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.5</td>\n",
       "      <td>17.800776</td>\n",
       "      <td>HOT</td>\n",
       "      <td>201</td>\n",
       "      <td>102.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.5</td>\n",
       "      <td>18.578861</td>\n",
       "      <td>HOT</td>\n",
       "      <td>1767</td>\n",
       "      <td>114.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      x1         x2    x3    x4          x5\n",
       "0    1.5   2.354153  COLD   593    0.750000\n",
       "1    2.5   3.314048  WARM   340    2.083333\n",
       "2    3.5   4.021604  COLD   551    4.083333\n",
       "3    4.5        NaN  COLD  2368    6.750000\n",
       "4    5.5   5.847601  WARM  2636   10.083333\n",
       "5    6.5   7.229910  WARM  2779   14.083333\n",
       "6    7.5   7.997255   HOT  1057   18.750000\n",
       "7    8.5   9.203947  COLD   819   24.083333\n",
       "8    9.5  10.335348  WARM  3349         NaN\n",
       "9   10.5  11.112142   HOT  3235   36.750000\n",
       "10  11.5  11.759611  WARM   216   44.083333\n",
       "11  12.5  12.629096  WARM  2529   52.083333\n",
       "12  13.5  14.082589  COLD  1735   60.750000\n",
       "13  14.5  14.657678   HOT  1254   70.083333\n",
       "14  15.5        NaN   HOT  1245   80.083333\n",
       "15  16.5  17.184114  WARM   310   90.750000\n",
       "16  17.5  17.800776   HOT   201  102.083333\n",
       "17  18.5  18.578861   HOT  1767  114.083333"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import numpy and pandas\n",
    "# import csv file\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "customer_trans = pd.read_csv(\"CustomTransformerData.csv\")\n",
    "customer_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzAXx3AmCZUS"
   },
   "source": [
    "# Create Custom Transformer\n",
    "\n",
    "Create a custom transformer, just as we did in the lecture video entitled \"Custom Transformers\", that performs two computations: \n",
    "\n",
    "1. Adds an attribute to the end of the data (i.e. new last column) that is equal to $\\frac{x_1^3}{x_5}$ for each observation\n",
    "\n",
    "2. Drops the entire $x_4$ feature column.  (See further instructions below.)\n",
    "\n",
    "You must name your custom transformer class `Assignment4Transformer`. Your class should include an input parameter with a default value of `True` that deletes the $x_4$ feature column when its value is `True`, but preserves the $x_4$ feature column when its value is `False`.\n",
    "\n",
    "This transformer will be used in a pipeline. In that pipeline, an imputer will be run *before* this transformer. Keep in mind that the imputer will output an array, so **this transformer must be written to accept an array.**\n",
    "\n",
    "Additionally, this transformer will ONLY be given the numerical features of the data. The categorical feature will be handled elsewhere in the full pipeline. This means that your code for this transformer **must reflect the absence of the categorical $x_3$ column** when indexing data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8V-S7sYjCZUT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.50000000e+00, 2.35415298e+00, 5.93000000e+02, 7.50000000e-01],\n",
       "       [2.50000000e+00, 3.31404772e+00, 3.40000000e+02, 2.08333333e+00],\n",
       "       [3.50000000e+00, 4.02160446e+00, 5.51000000e+02, 4.08333333e+00],\n",
       "       [4.50000000e+00, 1.05067957e+01, 2.36800000e+03, 6.75000000e+00],\n",
       "       [5.50000000e+00, 5.84760100e+00, 2.63600000e+03, 1.00833333e+01],\n",
       "       [6.50000000e+00, 7.22991004e+00, 2.77900000e+03, 1.40833333e+01],\n",
       "       [7.50000000e+00, 7.99725523e+00, 1.05700000e+03, 1.87500000e+01],\n",
       "       [8.50000000e+00, 9.20394654e+00, 8.19000000e+02, 2.40833333e+01],\n",
       "       [9.50000000e+00, 1.03353477e+01, 3.34900000e+03, 4.30245098e+01],\n",
       "       [1.05000000e+01, 1.11121419e+01, 3.23500000e+03, 3.67500000e+01],\n",
       "       [1.15000000e+01, 1.17596108e+01, 2.16000000e+02, 4.40833333e+01],\n",
       "       [1.25000000e+01, 1.26290958e+01, 2.52900000e+03, 5.20833333e+01],\n",
       "       [1.35000000e+01, 1.40825889e+01, 1.73500000e+03, 6.07500000e+01],\n",
       "       [1.45000000e+01, 1.46576780e+01, 1.25400000e+03, 7.00833333e+01],\n",
       "       [1.55000000e+01, 1.05067957e+01, 1.24500000e+03, 8.00833333e+01],\n",
       "       [1.65000000e+01, 1.71841140e+01, 3.10000000e+02, 9.07500000e+01],\n",
       "       [1.75000000e+01, 1.78007756e+01, 2.01000000e+02, 1.02083333e+02],\n",
       "       [1.85000000e+01, 1.85788610e+01, 1.76700000e+03, 1.14083333e+02]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create imputer to fill NaN with mean values.  Leave the imputer as an array\n",
    "# NOTES transformer needs to work with an array\n",
    "# Only numerical data is passed to a transformer\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "data_num = customer_trans[['x1', 'x2', 'x4', 'x5']]\n",
    "imputer = SimpleImputer(strategy = 'mean')\n",
    "imputer.fit(data_num)\n",
    "X = imputer.transform(data_num)\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CREATION OF TRANSFORMER\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# column index\n",
    "x1_ix, x2_ix, x4_ix, x5_ix = 0, 1, 2, 3\n",
    "\n",
    "class Assignment4Transformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, drop_x4 = True):\n",
    "        self.drop_x4 = drop_x4\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  \n",
    "\n",
    "# calculation to do X1 cubed / X5 and also drop X4 if set to true    \n",
    "    def transform(self, X):\n",
    "        x6 = X[:,x1_ix] **3 / X[:, x5_ix]\n",
    "        \n",
    "        if self.drop_x4:\n",
    "            drop_x4 = True\n",
    "            X = np.delete(X,[2],1)\n",
    "            return np.c_[X, x6]\n",
    "        else:\n",
    "            return np.c_[X, x6]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yMluWQYCZUT"
   },
   "source": [
    "# Create Transformation Pipeline for Numerical Features\n",
    "\n",
    "Create a custom transformation pipeline for numeric data only called `num_pipeline` that:\n",
    "\n",
    "1. Applies the `SimpleImputer` class to the data, where the strategy is set to `mean`.\n",
    "\n",
    "2. Applies the custom `Assignment4Transformer` class to the data.\n",
    "\n",
    "3. Applies the `StandardScaler` class to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OzVN4xJ-CZUT"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create the transformation pipeline of the numerical features.  Applies imputer, Trasnformer and Scaler\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer (strategy = 'mean')),\n",
    "    ('attribs_adder', Assignment4Transformer()),\n",
    "    ('std_scaler', StandardScaler ())])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRQDfs4xCZUU"
   },
   "source": [
    "# Create Numeric and Categorical DataFrames\n",
    "\n",
    "Create two new data frames.  Create one DataFrame called `data_num` that holds the numeric features.  Create another DataFrame called `data_cat` that holds the categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IitruXhKCZUU"
   },
   "outputs": [],
   "source": [
    "# New data frame for numerical data\n",
    "data_num = customer_trans[['x1', 'x2', 'x4', 'x5']]\n",
    "\n",
    "# New dataframe for categorical data\n",
    "data_cat = customer_trans [['x3']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6rj8eO8CZUU"
   },
   "source": [
    "# Quick Testing\n",
    "\n",
    "The full pipeline will be implemented with a `ColumnTransformer` class.  However, to be sure that our numeric pipeline is working properly, lets invoke the `fit_transform()` method of the `num_pipeline` object.  Then, take a look at the transformed data to be sure all is well.\n",
    "\n",
    "### Run Pipeline and Create Transformed Numeric Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EtGdsT8MCZUV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.63835604, -1.72914963, -1.19507691, -1.59050349],\n",
       "       [-1.44560827, -1.52555901, -1.15738431, -1.39982426],\n",
       "       [-1.2528605 , -1.37548847, -1.10084543, -1.20914502],\n",
       "       [-1.06011273,  0.        , -1.02546024, -1.01846579],\n",
       "       [-0.86736496, -0.9882004 , -0.93122876, -0.82778656],\n",
       "       [-0.67461719, -0.69501705, -0.81815098, -0.63710732],\n",
       "       [-0.48186942, -0.53226557, -0.68622691, -0.44642809],\n",
       "       [-0.28912165, -0.27633017, -0.53545654, -0.25574886],\n",
       "       [-0.09637388, -0.03636359,  0.        , -0.6099295 ],\n",
       "       [ 0.09637388,  0.128392  , -0.17737691,  0.12560961],\n",
       "       [ 0.28912165,  0.26571811,  0.02993235,  0.31628884],\n",
       "       [ 0.48186942,  0.4501331 ,  0.25608791,  0.50696808],\n",
       "       [ 0.67461719,  0.75841437,  0.50108976,  0.69764731],\n",
       "       [ 0.86736496,  0.88038895,  0.76493791,  0.88832654],\n",
       "       [ 1.06011273,  0.        ,  1.04763235,  1.07900578],\n",
       "       [ 1.2528605 ,  1.41623801,  1.34917309,  1.26968501],\n",
       "       [ 1.44560827,  1.54702995,  1.66956013,  1.46036424],\n",
       "       [ 1.63835604,  1.71205941,  2.00879346,  1.65104348]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this tests the pipline but we have not run the imputer or custom transformer.  This just test that the numeric pipeline\n",
    "column_transformed = num_pipeline.fit_transform(data_num)\n",
    "column_transformed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5-mJeXnCZUV"
   },
   "source": [
    "### One-Hot Encode Categorical Features\n",
    "\n",
    "Similarly, you will employ a `OneHotEncoder` class in the `ColumnTransformer` below to construct the final full pipeline.  However, let's instantiate an object of the `OneHotEncoder` class called `cat_encoder` that has the `drop` parameter set to `first`.  Next, call the `fit_transform()` method and pass it your categorical data.  Take a look at the transformed one-hot vectors to be sure all is well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ouqsgjpDCZUV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# on hot encoding creation.  Turns the categorical data into numeric values\n",
    "# Drop the first value\n",
    "cat_encoder = OneHotEncoder(drop='first')\n",
    "data_cat_1hot = cat_encoder.fit_transform(data_cat)\n",
    "data_cat_1hot.toarray()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZy5_wm4CZUW"
   },
   "source": [
    "# Put it All Together with a Column Transformer\n",
    "\n",
    "Now, we are finally ready to construct the full transformation pipeline called `full_pipeline` that will transform our raw data into clean, ready-to-train data.  Construct this ColumnTransformer below, then call the `fit_transform()` method to obtain the final, clean data.  Save this output data into a variable called `data_trans`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "HhutoLeaCZUW",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.63835604, -1.72914963, -1.19507691, -1.59050349,  0.        ,\n",
       "         0.        ],\n",
       "       [-1.44560827, -1.52555901, -1.15738431, -1.39982426,  0.        ,\n",
       "         1.        ],\n",
       "       [-1.2528605 , -1.37548847, -1.10084543, -1.20914502,  0.        ,\n",
       "         0.        ],\n",
       "       [-1.06011273,  0.        , -1.02546024, -1.01846579,  0.        ,\n",
       "         0.        ],\n",
       "       [-0.86736496, -0.9882004 , -0.93122876, -0.82778656,  0.        ,\n",
       "         1.        ],\n",
       "       [-0.67461719, -0.69501705, -0.81815098, -0.63710732,  0.        ,\n",
       "         1.        ],\n",
       "       [-0.48186942, -0.53226557, -0.68622691, -0.44642809,  1.        ,\n",
       "         0.        ],\n",
       "       [-0.28912165, -0.27633017, -0.53545654, -0.25574886,  0.        ,\n",
       "         0.        ],\n",
       "       [-0.09637388, -0.03636359,  0.        , -0.6099295 ,  0.        ,\n",
       "         1.        ],\n",
       "       [ 0.09637388,  0.128392  , -0.17737691,  0.12560961,  1.        ,\n",
       "         0.        ],\n",
       "       [ 0.28912165,  0.26571811,  0.02993235,  0.31628884,  0.        ,\n",
       "         1.        ],\n",
       "       [ 0.48186942,  0.4501331 ,  0.25608791,  0.50696808,  0.        ,\n",
       "         1.        ],\n",
       "       [ 0.67461719,  0.75841437,  0.50108976,  0.69764731,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.86736496,  0.88038895,  0.76493791,  0.88832654,  1.        ,\n",
       "         0.        ],\n",
       "       [ 1.06011273,  0.        ,  1.04763235,  1.07900578,  1.        ,\n",
       "         0.        ],\n",
       "       [ 1.2528605 ,  1.41623801,  1.34917309,  1.26968501,  0.        ,\n",
       "         1.        ],\n",
       "       [ 1.44560827,  1.54702995,  1.66956013,  1.46036424,  1.        ,\n",
       "         0.        ],\n",
       "       [ 1.63835604,  1.71205941,  2.00879346,  1.65104348,  1.        ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "num_attribs = list(data_num)\n",
    "cat_attribs = [\"x3\"]\n",
    "\n",
    "# full pipeline\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_attribs),\n",
    "    ('cat', OneHotEncoder (drop = 'first'), cat_attribs)])\n",
    "\n",
    "# creation of final data\n",
    "data_trans = full_pipeline.fit_transform(customer_trans)\n",
    "data_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8pHguZbCZUW"
   },
   "source": [
    "# Prepare for Grading\n",
    "\n",
    "Prepare your `data_trans` NumPy array for grading by using the NumPy [around()](https://numpy.org/doc/stable/reference/generated/numpy.around.html) function to round all the values to 2 decimal places - this will return a NumPy array.\n",
    "\n",
    "Please note the final order of the features in your final numpy array, which is given at the top of this document.\n",
    "\n",
    "___You MUST print your final answer, which is the NumPy array discussed above, using the `print()` function!  This MUST be the only `print()` statement in the entire notebook!  Do not print anything else using the print() function in this notebook!___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Tnva8j5OCZUX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.64 -1.73 -1.2  -1.59  0.    0.  ]\n",
      " [-1.45 -1.53 -1.16 -1.4   0.    1.  ]\n",
      " [-1.25 -1.38 -1.1  -1.21  0.    0.  ]\n",
      " [-1.06  0.   -1.03 -1.02  0.    0.  ]\n",
      " [-0.87 -0.99 -0.93 -0.83  0.    1.  ]\n",
      " [-0.67 -0.7  -0.82 -0.64  0.    1.  ]\n",
      " [-0.48 -0.53 -0.69 -0.45  1.    0.  ]\n",
      " [-0.29 -0.28 -0.54 -0.26  0.    0.  ]\n",
      " [-0.1  -0.04  0.   -0.61  0.    1.  ]\n",
      " [ 0.1   0.13 -0.18  0.13  1.    0.  ]\n",
      " [ 0.29  0.27  0.03  0.32  0.    1.  ]\n",
      " [ 0.48  0.45  0.26  0.51  0.    1.  ]\n",
      " [ 0.67  0.76  0.5   0.7   0.    0.  ]\n",
      " [ 0.87  0.88  0.76  0.89  1.    0.  ]\n",
      " [ 1.06  0.    1.05  1.08  1.    0.  ]\n",
      " [ 1.25  1.42  1.35  1.27  0.    1.  ]\n",
      " [ 1.45  1.55  1.67  1.46  1.    0.  ]\n",
      " [ 1.64  1.71  2.01  1.65  1.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "# prepare the data_trans by rounding\n",
    "print(np.around(data_trans,decimals=2))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Assignment_4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
